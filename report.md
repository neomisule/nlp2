Results:

1. Training MLE Models...
MLE 1-gram perplexity: 691.4702433653597
MLE 2-gram perplexity: inf
MLE 3-gram perplexity: inf
MLE 4-gram perplexity: inf

2. Training Add-1 Smoothed Trigram Model...
Add-1 smoothed trigram perplexity: 2930.2797642476817

3. Training Linear Interpolation Model...
Optimal lambdas: (0.3, 0.5, 0.2)
Linear interpolation perplexity: 212.13524034600206

4. Training Stupid Backoff Model...
Optimal alpha: 0.9
Stupid backoff perplexity: 92.10757584975707

5. Generating Text...

Generated Sentences:
1. henry full of <unk> & national security pacific corp inc corp
2. gloomy reports on speculation these positions complained that is also <unk> the proliferation <unk> mania of <unk> from the by mistake he
3. luzon of us into of losses that if law gerald f
4. hatch following the group $ n current copyright law he seeks fines of $ n million in congress but here say the
5. chiefs board stocks after the local soviet newspaper trading activity <unk> considerably across the bay said terms he are starting to be
